  
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width, height=device-height" />
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes">
<title></title>
<style>
  html, body {
      overflow: hidden;
    width: 100%;
    height: 100%;
    margin: 0;
    padding: 0;
  }
  .video {
      position: fixed; right: 0; bottom: 0;
      min-width: 100%; min-height: 100%;
      width: auto; height: auto; z-index: -100;
  }
</style>
</head>
<body onclick="captureImage()">
<!-- Load TensorFlow.js. This is required to use MobileNet. -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"> </script>
<!-- Load the MobileNet model. -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"> </script>

<!-- Replace this with your image. Make sure CORS settings allow reading the image! -->
<video class="video" id="video" width="100%" height="100%" autoplay="true" playsinline ></video>
<h3 id="message"> </h3>

<!-- Place your code in the script tag below. You can also use an external .js file -->
<script>
  // Notice there is no 'import' statement. 'mobilenet' and 'tf' is
  // available on the index-page because of the script tag above.

  var getJSON = function(url, callback) {
    var xhr = new XMLHttpRequest();
    xhr.open('GET', url, true);
    xhr.responseType = 'json';
    xhr.onload = function() {
      var status = xhr.status;
      if (status === 200) {
        callback(null, xhr.response);
      } else {
        callback(status, xhr.response);
      }
    };
    xhr.send();
};

  const video = document.getElementById('video');
 
  var constraints = window.constraints = {
    audio: false,
    video: {facingMode:"user"}
  };

function handleSuccess(stream) {
    video.srcObject = stream;
}

navigator.mediaDevices.getUserMedia(constraints).then(handleSuccess);

var scale = 1;
const IMAGE_SIZE = 224;

var synth = speechSynthesis;
var voices = synth.getVoices();

function captureImage() {
  var canvas = document.createElement("canvas");
  canvas.width = video.videoWidth * scale;
  canvas.height = video.videoHeight * scale;
  canvas.getContext('2d')
        .drawImage(video, 0, 0, canvas.width, canvas.height);
  var img = document.createElement("img");
  img.src = canvas.toDataURL();
img.width = IMAGE_SIZE;
img.height = IMAGE_SIZE;
  if (img.complete && img.naturalHeight !== 0) {
    document.getElementById("message").innerText ="Image loaded to memory!";
    detect(img);
} else {
img.onload = () => {
  document.getElementById("message").innerText ="Image loaded to memory!";
  detect(img);
};
};
}

//window.setInterval(function(){
//captureImage();
//}, 15000);


 /* if (navigator.mediaDevices.getUserMedia) {
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(function (stream) {
        video.srcObject = stream;
      })
      .catch(function (err0r) {
        console.log("Something went wrong!");
      });
  }*/

  //video.onloadeddata = (event) => {
  // Load the model.
function detect(imgElement){
  cocoSsd.load().then(model => {
    document.getElementById("message").innerText ="Model loaded to memory!";
    // Step 2: Grab and classify
    model.detect(imgElement).then((result) => {
    // Step 3: Print top result
    document.getElementById("message").innerText =result[0].class;

      getJSON('https://api.dictionaryapi.dev/api/v2/entries/en_US/'+result[0].class, function(err, data) {
        // JSON result in `data` variable
      if(data[0].meanings.length > 0){
        for(var i=0; i<data[0].meanings.length; i++){
          if(data[0].meanings[i].partOfSpeech=='noun'){
            document.getElementById("message").innerText = 
            `${result[0].class}:
             ${data[0].meanings[i].definitions[0].definition}`;
          }
        }
      }
      else
      {
        document.getElementById("message").innerText =`No object detected!`;
      }

      voices = synth.getVoices();
      var msg = new SpeechSynthesisUtterance();     
      //console.log("voices.length:"+voices.length);
      for(i = 0; i < voices.length ; i++) {
        //console.log(voices[i]);
        if(voices[i].name === "Microsoft Zira Desktop - English (United States)") {
          msg.voice = voices[i];
        }
      }

      // .text should be set, all other properties have defaults
      msg.text = document.getElementById("message").innerText;
      msg.pitch = 1;
      synth.speak(msg);

      });

    });
  });
};
  //};


</script>
</body>
</html>